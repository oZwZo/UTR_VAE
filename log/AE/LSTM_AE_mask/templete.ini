[DEFAULT]
#[TRAIN and VAL]
max_epoch = 600
setp_to_check = 10

#[RUN and SETTING]
batch_size = 
run_name = 
setting_name = 

#[DATA]
cell_line = "A549"

#[MODEL]
model_type =                     # LSTM_AE , LSTM_VAE

# optimizer
optimizer = 'Schedule'          #   'Schedule' , 'Adam' , {"weight_decay": ,"amsgrad": ,"n_warmup_steps": }
lr = 1e-3

#[LSTM HYPER-PARAM]

input_size = 5
hidden_size_enc = 64            # current best performance : 64 
hidden_size_dec = 64
num_layers = 2                  # current best performance : 2 with hidden =64
latent_dim = 16
seq_in_dim = 5 
discretize_input = True          # True / Flase   [0.007, 0.001] [0.004, 0.01]
decode_type = "seq"

teacher_forcing =                # True (will decay), fixed , [t_b->float, k_b->float]
bidirectional = False
fc_output = None                 # default None , or int 

#[CONV HYPER_PARAM]
enc_Conv_size =  [4,32,64]
dec_Conv_size =  [64,32,4]
